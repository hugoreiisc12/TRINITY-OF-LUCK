# üöÄ Future Features & Microservices Migration Guide

## Overview

This document outlines the planned future features for the Trinity API Gateway and provides a comprehensive roadmap for migrating from a monolithic architecture to a microservices-based system.

---

## üìã Future Features Overview

### 1. Multi-Niche Analysis Filtering (`/api/analyze`)

**Status**: Planned for 2026-Q2
**Current Placeholder**: `POST /api/analyze` (returns 501 Not Implemented)

#### Features to Implement:

```javascript
// Example Request
POST /api/analyze
{
  "contextId": "uuid",
  "niches": ["sports", "crypto", "politics"],
  "filters": {
    "includeHistorical": true,
    "timeRange": "7d",
    "minConfidence": 0.6,
    "excludeOutliers": true
  },
  "compareAcrossNiches": true,
  "advancedOptions": {
    "customWeights": { "sports": 0.5, "crypto": 0.3, "politics": 0.2 },
    "includeCorrelations": true,
    "predictConfidenceIntervals": true
  }
}
```

#### Implementation Tasks:

- [ ] Create niche metadata schema in database
- [ ] Train niche-specific ML models
- [ ] Implement cross-niche correlation analysis
- [ ] Add niche filtering logic to analysis pipeline
- [ ] Create niche comparison endpoints
- [ ] Build niche-specific metrics dashboard
- [ ] Add niche-specific caching layer
- [ ] Implement niche performance tracking

#### Database Schema Changes Needed:

```sql
-- Add niche metadata table
CREATE TABLE niche_metadata (
  id UUID PRIMARY KEY,
  niche_name VARCHAR(100) UNIQUE,
  description TEXT,
  ml_model_version VARCHAR(20),
  accuracy_metrics JSONB,
  last_retrained TIMESTAMP,
  data_points_count INT,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

-- Add niche references to analyses
ALTER TABLE analises ADD COLUMN nichos TEXT[] DEFAULT '{}';
ALTER TABLE analises ADD COLUMN niche_scores JSONB;
ALTER TABLE analises ADD COLUMN cross_niche_correlations JSONB;
```

#### Key Considerations:

- Data quality varies by niche (e.g., sports data vs crypto predictions)
- ML model accuracy differs significantly across niches
- Need separate rate limiting per niche
- Historical data availability varies by niche
- Cross-niche analysis requires sophisticated correlation algorithms

---

### 2. Data Export Functionality (`/api/export`)

**Status**: Planned for 2026-Q2
**Current Placeholder**: `POST /api/export` (returns 501 Not Implemented)

#### Features to Implement:

```javascript
// Example Request
POST /api/export
{
  "analysisIds": ["uuid1", "uuid2", "uuid3"],
  "format": "json|csv|pdf|excel|zip",
  "filters": {
    "dateRange": "7d",
    "includeMetadata": true,
    "includeExplanations": true,
    "minConfidence": 0.6
  },
  "options": {
    "compression": "gzip|bzip2|none",
    "includeCharts": true,
    "customTemplate": "standard|detailed|minimal"
  },
  "scheduling": {
    "enabled": false,
    "frequency": "daily|weekly|monthly",
    "timezone": "America/Sao_Paulo",
    "deliveryEmail": "user@example.com"
  }
}
```

#### Export Formats:

**JSON Export**
```json
{
  "exportDate": "2026-01-04T10:30:00Z",
  "format": "json",
  "analyses": [
    {
      "id": "uuid",
      "titulo": "...",
      "probabilidades": {},
      "confianca": 0.85,
      "explicacoes": [],
      "metadata": {},
      "exportedAt": "2026-01-04T10:30:00Z"
    }
  ],
  "summary": {
    "totalAnalyses": 3,
    "dateRange": "2026-01-01 to 2026-01-04",
    "averageConfidence": 0.82
  }
}
```

**CSV Export**
- Flattened structure with column headers
- Support for multi-line explanations
- Metadata as JSON strings in cells

**PDF Export**
- Professional formatted report
- Charts and visualizations
- Summary statistics
- Customizable branding

**Excel Export**
- Multiple sheets (one per analysis)
- Formatted cells with colors
- Summary sheet with statistics
- Pivot table support

**ZIP Export**
- Multiple files bundled together
- Compression to reduce file size
- Automatic naming convention
- Manifest file with metadata

#### Implementation Tasks:

- [ ] Implement JSON export formatter
- [ ] Implement CSV export with streaming
- [ ] Implement PDF generation (use PDFKit or similar)
- [ ] Implement Excel export (use xlsx library)
- [ ] Implement ZIP compression with archiver
- [ ] Add export templates system
- [ ] Implement scheduled export queue
- [ ] Add S3/cloud storage integration
- [ ] Implement export rate limiting
- [ ] Add email delivery for exports
- [ ] Create export history tracking
- [ ] Add export audit logging

#### Technology Stack:

```
PDF Generation: pdfkit, jsPDF, or html-pdf
Excel Export: xlsx, exceljs
CSV: fast-csv, papaparse
Compression: archiver, node-zip
Cloud Storage: aws-sdk, google-cloud-storage
Email Delivery: nodemailer, sendgrid
Streaming: Node.js streams API
```

#### File Size Considerations:

- Large exports (>100MB) should use streaming
- PDF generation is memory-intensive (implement batching)
- Cloud storage for exported files (reduce server load)
- Implement cleanup of old exports (30-day retention)

---

### 3. Microservices Migration Infrastructure

**Status**: Long-term strategic initiative
**Current Architecture**: Monolithic Node.js API Gateway

#### Migration Phases:

```
Phase 0 (Current - ‚úì Complete):
  - Monolithic architecture documented
  - Queue system (Bull) implemented
  - Core functionality working

Phase 1 (2026-Q2):
  - Service discovery setup
  - Inter-service communication (gRPC)
  - Circuit breaker patterns
  - Distributed tracing

Phase 2 (2026-Q3):
  - Extract Analysis Service
  - Extract User Service
  - Extract Subscription Service
  - Database separation begins

Phase 3 (2026-Q4):
  - Event sourcing implementation
  - Saga patterns for transactions
  - Data synchronization layer

Phase 4 (2027-Q1):
  - Kubernetes deployment
  - Service mesh (Istio)
  - Full microservices architecture
```

#### Phase 1: Service Discovery & Communication

**Service Discovery**
```yaml
# Service Registry (using Consul or similar)
services:
  - name: api-gateway
    host: api-gateway.service.consul
    port: 3001
  - name: analysis-service
    host: analysis-service.service.consul
    port: 3002
  - name: user-service
    host: user-service.service.consul
    port: 3003
```

**gRPC Service Definition**
```protobuf
service AnalysisService {
  rpc Analyze (AnalyzeRequest) returns (AnalyzeResponse);
  rpc GetAnalysis (GetAnalysisRequest) returns (Analysis);
  rpc UpdateAnalysis (UpdateAnalysisRequest) returns (Analysis);
}

service UserService {
  rpc GetUser (GetUserRequest) returns (User);
  rpc UpdateUser (UpdateUserRequest) returns (User);
  rpc GetSubscription (GetSubscriptionRequest) returns (Subscription);
}
```

**Circuit Breaker Pattern**
```javascript
const circuitBreaker = new CircuitBreaker(
  async (request) => {
    return await serviceClient.call(request);
  },
  {
    timeout: 3000,
    errorThresholdPercentage: 50,
    resetTimeout: 30000,
  }
);
```

#### Phase 2: Service Separation

**Analysis Service**
- Extract: `/api/results/*`, `/api/analyze*`
- Dependencies: Database (analises table), Python service
- Queue: Analysis queue
- Technology: Node.js, Express, PostgreSQL

**User Service**
- Extract: `/api/auth/*`, `/api/settings`
- Dependencies: Database (usuarios table), Supabase Auth
- Technology: Node.js, Express, PostgreSQL

**Subscription Service**
- Extract: `/api/stripe/*`, `/api/subscription*`, `/api/plans`
- Dependencies: Database (planos, assinaturas), Stripe API
- Webhooks: Stripe webhook handling
- Technology: Node.js, Express, PostgreSQL

**Import Service**
- Extract: `/api/import-context`, `/api/upload`, `/api/export`
- Dependencies: Database (contextos), File storage, Python service
- Technology: Node.js, Express, PostgreSQL, S3

**Queue Service**
- Extract: Bull queue processing
- Workers: Analysis, Email, Notification, Report, Retraining
- Dependencies: Redis, Database
- Technology: Node.js, Bull, Redis

#### Phase 3: Database Separation

**Current State (Shared Database)**
```
API Gateway
    ‚îú‚îÄ‚îÄ usuarios
    ‚îú‚îÄ‚îÄ contextos
    ‚îú‚îÄ‚îÄ analises
    ‚îú‚îÄ‚îÄ assinaturas
    ‚îú‚îÄ‚îÄ planos
    ‚îú‚îÄ‚îÄ feedbacks
    ‚îî‚îÄ‚îÄ plataformas
```

**After Migration (Database Per Service)**
```
User Service Database
    ‚îî‚îÄ‚îÄ usuarios

Subscription Service Database
    ‚îú‚îÄ‚îÄ planos
    ‚îú‚îÄ‚îÄ assinaturas

Analysis Service Database
    ‚îî‚îÄ‚îÄ analises

Import Service Database
    ‚îú‚îÄ‚îÄ contextos
    ‚îî‚îÄ‚îÄ plataformas

Shared Database (Reduced)
    ‚îî‚îÄ‚îÄ feedbacks (for cross-service analytics)
```

**Event Sourcing Implementation**
```javascript
// Events published by services
UserCreatedEvent
UserSubscribedEvent
AnalysisCompletedEvent
FeedbackReceivedEvent
ImportProcessedEvent

// Event subscribers
- Analysis Service subscribes to UserCreatedEvent
- Subscription Service subscribes to PaymentSucceededEvent
- Import Service subscribes to AnalysisCompletedEvent
```

**Saga Pattern for Distributed Transactions**
```javascript
// Create Subscription Saga
1. Subscription Service: Create subscription (pending)
2. Queue Service: Queue welcome email
3. User Service: Update subscription count
4. Subscription Service: Confirm subscription
   - On failure: Rollback all changes
   - On success: Publish SubscriptionCreatedEvent
```

#### Phase 4: Infrastructure & DevOps

**Containerization**
```dockerfile
# Example Dockerfile for Analysis Service
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --production
COPY . .
EXPOSE 3002
CMD ["node", "server.js"]
```

**Kubernetes Deployment**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: analysis-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: analysis-service
  template:
    metadata:
      labels:
        app: analysis-service
    spec:
      containers:
      - name: analysis-service
        image: trinity/analysis-service:latest
        ports:
        - containerPort: 3002
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
```

**Service Mesh (Istio)**
- Load balancing between service instances
- Circuit breaking and retry policies
- Security policies and mTLS
- Observability and metrics

---

## üó∫Ô∏è Current Architecture Issues

### 1. Shared Database

**Problem**: All services in one monolith access same database
**Impact**: 
- Difficult to scale services independently
- Risk of cross-service data corruption
- Tight coupling between services

**Solution**: Event sourcing + database per service pattern

### 2. Direct Service Calls

**Problem**: Python service calls via direct axios
```javascript
const response = await axios.post(`${pythonApiUrl}/analyze`, pythonInput);
```

**Impact**:
- Tight coupling to Python service
- No service discovery
- No circuit breaker protection
- Network failures crash API Gateway

**Solution**: gRPC with service discovery and circuit breaker

### 3. Queue System Tightly Coupled

**Problem**: Bull queues directly in API Gateway
```javascript
const job = await queueAnalysis(req.user.id, data);
```

**Impact**:
- Queue system scales with API Gateway
- Cannot scale workers independently
- Complex dependency tree

**Solution**: Separate Queue Service with Redis

### 4. Authentication in Middleware

**Problem**: Every route validates JWT
**Impact**:
- Auth logic duplicated across services
- Changes to auth require updating all services

**Solution**: API Gateway as auth proxy

### 5. Webhook Handling Tightly Coupled

**Problem**: Stripe webhooks directly update subscriptions
**Impact**:
- Subscription Service tightly coupled to payment processing
- Error handling is complex
- Difficult to test

**Solution**: Event-driven webhook handling

---

## üìä Migration Timeline

```
Timeline: 2026 (Current Year + 1)

Q1 (Jan-Mar):
  - Documentation & Planning
  - Infrastructure setup (Kubernetes, service discovery)
  - Start Phase 1 preparation

Q2 (Apr-Jun):
  - Phase 1 complete: gRPC, service discovery, tracing
  - Phase 2 begins: Extract first microservice
  - Deploy Analysis Service as standalone
  - Run parallel to monolith

Q3 (Jul-Sep):
  - Phase 2 continues: Extract User & Subscription services
  - Phase 3 begins: Database separation
  - Event sourcing implementation
  - Data synchronization layer

Q4 (Oct-Dec):
  - Phase 2 complete: All services extracted
  - Phase 3 complete: Full database separation
  - Phase 4 setup: Kubernetes ready
  - Comprehensive testing

2027 Q1+:
  - Phase 4: Full microservices deployment
  - Service mesh (Istio) operational
  - Monitor and optimize
  - Decommission monolithic gateway
```

---

## üõ†Ô∏è Technology Recommendations

### Service Communication
- **gRPC**: Inter-service communication (request/response)
- **Event Bus**: Apache Kafka or RabbitMQ for events
- **API Gateway**: Kong or Envoy for external API

### Service Discovery
- **Consul**: Service registry and discovery
- **etcd**: Kubernetes-native discovery

### Deployment & Orchestration
- **Docker**: Containerization
- **Kubernetes**: Container orchestration
- **Helm**: Kubernetes package manager

### Observability
- **Prometheus**: Metrics collection
- **Grafana**: Metrics visualization
- **Jaeger**: Distributed tracing
- **ELK Stack**: Centralized logging

### Database
- **PostgreSQL**: Relational databases per service
- **Redis**: Cache and queue backend
- **MongoDB** (optional): For document-based services

---

## üìà Expected Benefits

After complete migration:

1. **Scalability**: Scale services independently based on load
2. **Reliability**: Fault isolation prevents cascading failures
3. **Development**: Teams can work on services independently
4. **Deployment**: Deploy services without affecting others
5. **Technology**: Use best tool for each service
6. **Monitoring**: Better observability and debugging
7. **Testing**: Easier to test services in isolation

---

## üìö Additional Resources

### Microservices Patterns
- https://microservices.io/patterns/index.html
- https://martinfowler.com/articles/microservices.html

### Technologies
- gRPC: https://grpc.io/
- Kubernetes: https://kubernetes.io/
- Istio: https://istio.io/
- Event-driven: https://www.confluent.io/

### Related Code References
- Current server.js: Monolithic routes
- queue.js: Bull queue implementation
- database.js: Database schema and initialization
- logging.js: Centralized logging system

---

## üéØ Next Steps

1. **Phase 0 Complete** ‚úì
   - Monolithic architecture documented
   - All features working

2. **Phase 1 Planning** (Next)
   - Design service contracts
   - Set up development infrastructure
   - Create gRPC definitions
   - Plan service registry setup

3. **Phase 2 Preparation**
   - Identify Analysis Service as first candidate
   - Prepare database schema migration
   - Create integration tests

4. **Execution**
   - Start with Phase 1 in next sprint
   - Run parallel microservices alongside monolith
   - Migrate services progressively
   - Monitor and optimize

---

**Last Updated**: 2026-01-04
**Status**: Planning Phase
**Assigned To**: Trinity Development Team
**Priority**: High (Strategic Initiative)
